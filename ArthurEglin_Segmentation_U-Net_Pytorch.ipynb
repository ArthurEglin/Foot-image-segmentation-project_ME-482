{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation U-Net model for retina blood vessel segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# resizing and basic image procressing\n",
    "import cv2\n",
    "\n",
    "# data extraction\n",
    "from glob import glob\n",
    "\n",
    "# display progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# read the gif masks\n",
    "import imageio\n",
    "\n",
    "# data augmentation library\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# training\n",
    "import time\n",
    "\n",
    "# test\n",
    "from operator import add\n",
    "import imageio\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to fix the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create directories for data sorting and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x = sorted(list(map(lambda x: x.replace('\\\\', '/'), glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))))\n",
    "    train_y = sorted(list(map(lambda x: x.replace('\\\\', '/'), glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))))\n",
    "\n",
    "    test_x = sorted(list(map(lambda x: x.replace('\\\\', '/'), glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))))\n",
    "    test_y = sorted(list(map(lambda x: x.replace('\\\\', '/'), glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))))\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    # define image size\n",
    "    size = (512, 512)\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        # extract the name of the image\n",
    "        name = x.split(\"/\")[-1].split('.')[0]\n",
    "        \n",
    "        # read the image and the mask\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = imageio.mimread(y)[0]\n",
    "\n",
    "        if augment == True:\n",
    "            aug = HorizontalFlip(p=1.0) # p is the probability of applying HorizontalFlip\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "\n",
    "            aug = Rotate(limit=45, p=1.0) # 45 degree rotation\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "\n",
    "            X = [x, x1, x2, x3]\n",
    "            Y = [y, y1, y2, y3]\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        index = 0\n",
    "        \n",
    "        for i, m in zip(X, Y):\n",
    "            # resize the arrays\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            # create temporary file names\n",
    "            tmp_image_name = \"{}_{}.png\".format(name, index)\n",
    "            tmp_mask_name = \"{}_{}.png\".format(name, index)\n",
    "\n",
    "            # save images\n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "            \n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1st convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        # batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        # 2nd convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1) # WARNING put out_c as input here!\n",
    "        # batch normalization\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        # activation function\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c) # addition is less computationally expensive\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1) # concatenate the convolutions\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define encoder part\n",
    "        self.e1 = encoder_block(3, 64) # in_channels: 3 since RGB image composed of 3 channels, out_channels: 64\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        # define the bottleneck layer (bridge layer) --> just a convolution block\n",
    "        self.b = conv_block(512, 1024)\n",
    "\n",
    "        # define the decoder part\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        # define the classifier\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0) # out_channels: 1 since we want a binary mask as output\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # encoder\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        # bottleneck\n",
    "        b = self.b(p4)\n",
    "\n",
    "        # decoder\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "        \n",
    "        # output\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # reading image\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image/255.0 # dimension: (512, 512, 3)\n",
    "        image = np.transpose(image, (2, 0, 1))  # dimension: (3, 512, 512)\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        # reading mask\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask/255.0   # dimension: (512, 512)\n",
    "        mask = np.expand_dims(mask, axis=0) # dimension: (1, 512, 512)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # transpose inputs with sigmoid\n",
    "        inputs = torch.sigmoid(inputs) # comment out if the model already contain a sigmoid (or equivalent) activation layer\n",
    "\n",
    "        # flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid (or equivalent) activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_function, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_function, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_function(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the random seed to get the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the files to save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir('data/')\n",
    "create_dir('data/retina_segmentation_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir('data/retina_segmentation_data/augmented_data/train/image/')\n",
    "create_dir('data/retina_segmentation_data/augmented_data/train/mask/')\n",
    "create_dir('data/retina_segmentation_data/augmented_data/test/image/')\n",
    "create_dir('data/retina_segmentation_data/augmented_data/test/mask/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/retina_segmentation_data/'\n",
    "(train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
    "\n",
    "print('Dataset size:')\n",
    "print('Train: \\n x: {} \\n y: {}'.format(len(train_x), len(train_y)))\n",
    "print('Test: \\n x: {} \\n y: {}'.format(len(test_x), len(test_y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIFY : create TRAINING SET, VALIDATION SET and TEST SET. To augment data even more do:\n",
    "- a lot of rotation augmentation (au moins 360x 1 degr√©)\n",
    "- all the flipping possibilities\n",
    "- bluring\n",
    "- surement d'autres processus pour augmenter le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training data\n",
    "augment_data(images=train_x, masks=train_y, save_path='data/retina_segmentation_data/augmented_data/train/', augment=True)\n",
    "# create the test data\n",
    "augment_data(images=test_x, masks=test_y, save_path='data/retina_segmentation_data/augmented_data/test/', augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = sorted(glob(\"data/retina_segmentation_data/augmented_data/train/image/*\"))[:40]\n",
    "train_y = sorted(glob(\"data/retina_segmentation_data/augmented_data/train/mask/*\"))[:40]\n",
    "\n",
    "valid_x = sorted(glob(\"data/retina_segmentation_data/augmented_data/test/image/*\"))\n",
    "valid_y = sorted(glob(\"data/retina_segmentation_data/augmented_data/test/mask/*\"))\n",
    "\n",
    "print('Dataset size:')\n",
    "print('Train: \\n x: {} \\n y: {}'.format(len(train_x), len(train_y)))\n",
    "print('Test: \\n x: {} \\n y: {}'.format(len(valid_x), len(valid_y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "SIZE = (HEIGHT, WIDTH)\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "CHECKPOINT_PATH = \"data/retina_segmentation_data/model_saved/checkpoint.pth\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DriveDataset(train_x, train_y)\n",
    "valid_dataset = DriveDataset(valid_x, valid_y)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = build_unet()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_function = DiceBCELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, loss_function, device)\n",
    "    valid_loss = evaluate(model, valid_loader, loss_function, device)\n",
    "\n",
    "    # saving the model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        print('Validation loss improved from {:2.4f} to {:2.4f}. Saving checkpoint: {}'.format(best_valid_loss, valid_loss, CHECKPOINT_PATH))\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print('Epoch: {} | Epoch time: {}min {}s\\n\\tTraining loss: {:.3f}\\n\\tValidation loss: {:.3f}\\n'.format(epoch, epoch_mins, epoch_secs, train_loss, valid_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Ground truth\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1) # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1) # (512, 512, 3)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir('data/retina_segmentation_data/results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = sorted(glob(\"data/retina_segmentation_data/augmented_data/test/image/*\"))\n",
    "test_y = sorted(glob(\"data/retina_segmentation_data/augmented_data/test/mask/*\"))\n",
    "\n",
    "print('Dataset size:')\n",
    "print('Train: \\n x: {} \\n y: {}'.format(len(test_x), len(test_y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = build_unet()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model and creating images for output comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "time_taken = []\n",
    "\n",
    "for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "    # Extract the name\n",
    "    print('1')\n",
    "    name = x.replace('\\\\', '/').split(\"/\")[-1].split(\".\")[0]\n",
    "    print(name)\n",
    "    # reading image\n",
    "    image = cv2.imread(x, cv2.IMREAD_COLOR) \n",
    "    image = cv2.resize(image, SIZE) # (512, 512, 3)\n",
    "    x = np.transpose(image, (2, 0, 1)) # (3, 512, 512)\n",
    "    x = x/255.0 # normalize the pixels\n",
    "    x = np.expand_dims(x, axis=0) # (1, 3, 512, 512)\n",
    "    x = x.astype(np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.to(device)\n",
    "\n",
    "    # reading mask\n",
    "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  \n",
    "    mask = cv2.resize(mask, SIZE) # (512, 512)\n",
    "    y = np.expand_dims(mask, axis=0) # (1, 512, 512)\n",
    "    y = y/255.0 # normalize the pixels\n",
    "    y = np.expand_dims(y, axis=0) # (1, 1, 512, 512)\n",
    "    y = y.astype(np.float32)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Prediction and Calculating FPS\n",
    "        start_time = time.time()\n",
    "        pred_y = model(x)\n",
    "        pred_y = torch.sigmoid(pred_y)\n",
    "        total_time = time.time() - start_time\n",
    "        time_taken.append(total_time)\n",
    "\n",
    "        # calculate the metrics\n",
    "        score = calculate_metrics(y, pred_y)\n",
    "        metrics_score = list(map(add, metrics_score, score))\n",
    "        pred_y = pred_y[0].cpu().numpy() # (1, 512, 512)\n",
    "        pred_y = np.squeeze(pred_y, axis=0) # (512, 512)\n",
    "        pred_y = pred_y > 0.5\n",
    "        pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "    # Saving masks\n",
    "    original_mask = mask_parse(mask)\n",
    "    pred_y = mask_parse(pred_y)\n",
    "    line = np.ones((SIZE[1], 10, 3)) * 128\n",
    "\n",
    "    concatenated_images = np.concatenate([image, line, original_mask, line, pred_y*255], axis=1)\n",
    "    cv2.imwrite(\"data/retina_segmentation_data/results/{}.png\".format(name), concatenated_images)\n",
    "\n",
    "jaccard = metrics_score[0]/len(test_x)\n",
    "f1 = metrics_score[1]/len(test_x)\n",
    "recall = metrics_score[2]/len(test_x)\n",
    "precision = metrics_score[3]/len(test_x)\n",
    "accuracy = metrics_score[4]/len(test_x)\n",
    "print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {accuracy:1.4f}\")\n",
    "\n",
    "fps = 1/np.mean(time_taken)\n",
    "print(\"FPS: \", fps)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
